{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "168d9860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4682b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 11 \n",
    "\n",
    "img_height = 64\n",
    "img_width = 64\n",
    "\n",
    "model = Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adc51a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6862 files belonging to 11 classes.\n",
      "Using 5490 files for training.\n",
      "Found 6862 files belonging to 11 classes.\n",
      "Using 1372 files for validation.\n",
      "Epoch 1/25\n",
      "172/172 [==============================] - 21s 115ms/step - loss: 1.5180 - accuracy: 0.4862 - val_loss: 1.1821 - val_accuracy: 0.6006\n",
      "Epoch 2/25\n",
      "172/172 [==============================] - 20s 114ms/step - loss: 1.0612 - accuracy: 0.6412 - val_loss: 1.0635 - val_accuracy: 0.6480\n",
      "Epoch 3/25\n",
      "172/172 [==============================] - 20s 114ms/step - loss: 0.9494 - accuracy: 0.6747 - val_loss: 1.0494 - val_accuracy: 0.6531\n",
      "Epoch 4/25\n",
      "172/172 [==============================] - 18s 106ms/step - loss: 0.8699 - accuracy: 0.7018 - val_loss: 1.0128 - val_accuracy: 0.6560\n",
      "Epoch 5/25\n",
      "172/172 [==============================] - 19s 110ms/step - loss: 0.7880 - accuracy: 0.7319 - val_loss: 0.8955 - val_accuracy: 0.7048\n",
      "Epoch 6/25\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 0.7212 - accuracy: 0.7557 - val_loss: 0.9271 - val_accuracy: 0.6844\n",
      "Epoch 7/25\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 0.6621 - accuracy: 0.7785 - val_loss: 0.9618 - val_accuracy: 0.6968\n",
      "Epoch 8/25\n",
      "172/172 [==============================] - 18s 105ms/step - loss: 0.5947 - accuracy: 0.7967 - val_loss: 0.8518 - val_accuracy: 0.7310\n",
      "Epoch 9/25\n",
      "172/172 [==============================] - 18s 104ms/step - loss: 0.5186 - accuracy: 0.8270 - val_loss: 0.9626 - val_accuracy: 0.6902\n",
      "Epoch 10/25\n",
      "172/172 [==============================] - 19s 107ms/step - loss: 0.4573 - accuracy: 0.8444 - val_loss: 0.9485 - val_accuracy: 0.7238\n",
      "Epoch 11/25\n",
      "172/172 [==============================] - 18s 105ms/step - loss: 0.3891 - accuracy: 0.8727 - val_loss: 0.9285 - val_accuracy: 0.7296\n",
      "Epoch 12/25\n",
      "172/172 [==============================] - 19s 107ms/step - loss: 0.3452 - accuracy: 0.8869 - val_loss: 1.0036 - val_accuracy: 0.7201\n",
      "Epoch 13/25\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 0.3036 - accuracy: 0.9009 - val_loss: 0.9876 - val_accuracy: 0.7332\n",
      "Epoch 14/25\n",
      "172/172 [==============================] - 19s 110ms/step - loss: 0.2582 - accuracy: 0.9140 - val_loss: 1.1475 - val_accuracy: 0.7114\n",
      "Epoch 15/25\n",
      "172/172 [==============================] - 19s 112ms/step - loss: 0.2214 - accuracy: 0.9268 - val_loss: 1.1377 - val_accuracy: 0.7413\n",
      "Epoch 16/25\n",
      "172/172 [==============================] - 20s 116ms/step - loss: 0.1963 - accuracy: 0.9355 - val_loss: 1.2837 - val_accuracy: 0.7267\n",
      "Epoch 17/25\n",
      "172/172 [==============================] - 19s 112ms/step - loss: 0.1429 - accuracy: 0.9539 - val_loss: 1.2678 - val_accuracy: 0.7318\n",
      "Epoch 18/25\n",
      "172/172 [==============================] - 20s 113ms/step - loss: 0.1236 - accuracy: 0.9612 - val_loss: 1.2450 - val_accuracy: 0.7347\n",
      "Epoch 19/25\n",
      "172/172 [==============================] - 19s 110ms/step - loss: 0.1290 - accuracy: 0.9592 - val_loss: 1.3659 - val_accuracy: 0.7493\n",
      "Epoch 20/25\n",
      "172/172 [==============================] - 20s 114ms/step - loss: 0.0943 - accuracy: 0.9707 - val_loss: 1.4036 - val_accuracy: 0.7391\n",
      "Epoch 21/25\n",
      "172/172 [==============================] - 18s 106ms/step - loss: 0.0938 - accuracy: 0.9707 - val_loss: 1.4534 - val_accuracy: 0.7347\n",
      "Epoch 22/25\n",
      "172/172 [==============================] - 19s 108ms/step - loss: 0.0785 - accuracy: 0.9767 - val_loss: 1.5271 - val_accuracy: 0.7252\n",
      "Epoch 23/25\n",
      "172/172 [==============================] - 18s 105ms/step - loss: 0.0736 - accuracy: 0.9807 - val_loss: 1.5676 - val_accuracy: 0.7347\n",
      "Epoch 24/25\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 0.0544 - accuracy: 0.9847 - val_loss: 1.6736 - val_accuracy: 0.7281\n",
      "Epoch 25/25\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 0.0643 - accuracy: 0.9814 - val_loss: 1.7006 - val_accuracy: 0.7245\n"
     ]
    }
   ],
   "source": [
    "epochs = 25 # liczba epok treningu\n",
    "\n",
    "data_dir = 'dataset'\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0cc67f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 2s 30ms/step - loss: 1.7006 - accuracy: 0.7245\n",
      "Accuracy:  0.7244898080825806\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(val_ds)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b28aba77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 206ms/step\n",
      "To zdjęcie najprawdopodobniej przedstawia sandstorm z prawdopodobieństwem 100.00%\n"
     ]
    }
   ],
   "source": [
    "img_path = 'test/sandman.jpg'\n",
    "class_names = ['dew', 'fogsmog', 'frost', 'glaze', 'hail', 'lightning', 'rain', 'rainbow', 'rime', 'sandstorm', 'snow']\n",
    "\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    img_path, target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"To zdjęcie najprawdopodobniej przedstawia {} z prawdopodobieństwem {:.2f}%\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e6bcbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf29-pt3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
